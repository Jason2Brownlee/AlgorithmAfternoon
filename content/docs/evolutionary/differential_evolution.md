# Differential Evolution

## Name

Differential Evolution (DE)

## Taxonomy

Differential Evolution is a stochastic population-based optimization algorithm that belongs to the field of Evolutionary Computation, a subfield of Computational Intelligence. It is closely related to other Evolutionary Algorithms such as Genetic Algorithms and Evolution Strategies.

- Computational Intelligence
  - Biologically Inspired Computation
    - Evolutionary Computation
      - Evolutionary Algorithms
        - Genetic Algorithms
        - Evolution Strategies
        - Differential Evolution

## Strategy

### Population Initialization

Differential Evolution begins by initializing a population of candidate solutions, typically represented as real-valued vectors, within the search space. The population size remains constant throughout the optimization process.

### Mutation

For each candidate solution (target vector) in the current population, a mutant vector is generated by adding the weighted difference between two randomly selected population members to a third randomly selected member. This mutation strategy introduces new genetic information and maintains diversity in the population.

### Crossover

To enhance the potential diversity of the population, a crossover operation is performed between the target vector and the mutant vector, resulting in a trial vector. The crossover is typically controlled by a user-defined crossover probability, which determines the fraction of parameters that are inherited from the mutant vector.

### Selection

The trial vector competes with the corresponding target vector for survival in the next generation. If the trial vector has an equal or better objective function value compared to the target vector, it replaces the target vector in the population; otherwise, the target vector is retained. This greedy selection mechanism ensures that the population quality does not degrade over generations.

### Termination

The mutation, crossover, and selection steps are repeated until a termination criterion is met, such as reaching a maximum number of generations or achieving a satisfactory objective function value.

## Procedure

1. Initialize the population:
   1. Define the population size, problem dimensionality, and parameter bounds.
   2. Randomly initialize the population of candidate solutions within the parameter bounds.
2. While the termination criterion is not met, for each candidate solution (target vector) in the population:
   1. Mutation:
      1. Randomly select three distinct population members.
      2. Calculate the weighted difference between two of the selected members.
      3. Add the weighted difference to the third selected member to create a mutant vector.
   2. Crossover:
      1. Perform crossover between the target vector and the mutant vector based on the crossover probability.
      2. Create a trial vector by inheriting parameters from either the target vector or the mutant vector.
   3. Selection:
      1. Evaluate the objective function for the trial vector.
      2. If the trial vector has an equal or better objective function value compared to the target vector, replace the target vector with the trial vector in the population.
3. Return the best solution found in the population.

Relevant data structures and parameters:
- Population: A set of candidate solutions, typically represented as real-valued vectors.
- Population size: The number of candidate solutions in the population.
- Problem dimensionality: The number of parameters in each candidate solution.
- Parameter bounds: The lower and upper bounds for each parameter.
- Mutation factor: A scaling factor that controls the magnitude of the difference vector in the mutation step.
- Crossover probability: The probability of inheriting parameters from the mutant vector during crossover.

## Considerations

Advantages:
- Simple and straightforward to implement, with few control parameters.
- Effective in solving a wide range of optimization problems, including non-differentiable, nonlinear, and multimodal functions.
- Exhibits good convergence properties and maintains population diversity, reducing the risk of premature convergence.

Disadvantages:
- Performance may be sensitive to the choice of control parameters, requiring some tuning for optimal results.
- Convergence speed can be slower compared to some other optimization algorithms, especially for high-dimensional problems.
- Lacks an explicit mechanism for handling constraints, requiring additional techniques for constrained optimization problems.

## Heuristics

### Population Size

- A larger population size can improve the exploration of the search space but increases computational cost.
- A smaller population size may lead to faster convergence but risks premature convergence to suboptimal solutions.
- As a rule of thumb, a population size of 5 to 10 times the problem dimensionality is often effective.

### Mutation Factor

- The mutation factor controls the magnitude of the perturbation in the mutation step.
- Higher values (e.g., 0.5 to 1.0) encourage exploration, while lower values (e.g., 0.1 to 0.5) promote exploitation.
- A common strategy is to start with a higher mutation factor and gradually decrease it over generations to balance exploration and exploitation.

### Crossover Probability

- The crossover probability determines the extent of information exchange between the target and mutant vectors.
- Higher values (e.g., 0.9 to 1.0) favor the mutant vector, promoting diversity, while lower values (e.g., 0.1 to 0.5) favor the target vector, promoting convergence.
- A crossover probability of around 0.5 often provides a good balance between exploration and exploitation.

### Termination Criteria

- The maximum number of generations should be set based on the problem complexity and available computational resources.
- Convergence-based criteria, such as the relative improvement in the best solution over a certain number of generations, can be used to terminate the algorithm when progress stagnates.
- Other criteria, such as reaching a target objective function value or a maximum number of function evaluations, can also be considered.

### Parameter Adaptation

- Adapting the control parameters (mutation factor and crossover probability) during the optimization process can improve the algorithm's performance.
- Self-adaptive schemes, where the parameters are encoded within the candidate solutions and evolve alongside them, have been successful in some variants of Differential Evolution.
- Deterministic parameter control strategies, such as linearly decreasing the mutation factor over generations, can also be effective.
